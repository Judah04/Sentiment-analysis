{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3e244097-e7b4-4489-a21f-ff2e55ab916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "#import warnings\n",
    "import re\n",
    "#import emoji\n",
    "#warnings.filterwarnings('ignore')  # Ignore all warnings\n",
    "\n",
    "file_path = \"twitter_data.csv\"\n",
    "final_df = pd.read_csv(file_path)\n",
    "df = final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "59389977-1823-4c4c-b04a-0f80de7a9f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigning columns\n",
    "\n",
    "#Reset the index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "#Define new column names\n",
    "new_columns = [\n",
    "    'index',\n",
    "    'user',\n",
    "    'tweet',\n",
    "    'VAR',\n",
    "    'twitterlink',\n",
    "    'username'\n",
    "]\n",
    "\n",
    "#Update column names with str.strip() to remove whitespace\n",
    "df.columns = [column.strip() for column in new_columns]\n",
    "\n",
    "#Handle duplicate column names\n",
    "df.columns = df.columns.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "de31fcf7-8c22-4513-8a77-c9dcd87ffb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the index column\n",
    "df = df.drop(columns=['index'], axis=1)\n",
    "\n",
    "#Remove the VAR column\n",
    "df = df.drop(columns=['VAR'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "3c1af435-3987-4e7a-b4c6-5dd83937d097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the user, tweet and username columns to strings\n",
    "df[['user', 'tweet', 'username']] = df[['user', 'tweet', 'username']].astype(str)\n",
    "\n",
    "#print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "368f88fb-7086-477f-adbe-0cfbed5295f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning first column (users)\n",
    "\n",
    "# This method removes leading (left) double-quote characters from the string\n",
    "df['user'] = df['user'].apply(lambda x: x.lstrip('\"'))\n",
    "\n",
    "#Define a function to handle usernames and remove characters after '-'\n",
    "def process_username(text):\n",
    "    #Extract username if it starts with '@'\n",
    "    matches = re.findall(r'@(\\w+)', text)\n",
    "    if matches:\n",
    "        return '@' + matches[0]\n",
    "\n",
    "    #Remove characters after '-'\n",
    "    if \"-\" in text:\n",
    "        return re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "#Apply the function to the \"user\" column\n",
    "df[\"user\"] = df[\"user\"].apply(process_username)\n",
    "\n",
    "#Define a function to remove characters after \"on X:\" including it\n",
    "def remove_after_on_x(text):\n",
    "    return text.split(\"on X:\")[0]\n",
    "\n",
    "#Apply the function to the \"user\" column\n",
    "df[\"user\"] = df[\"user\"].apply(remove_after_on_x)\n",
    "\n",
    "#Romove words after 3rd word\n",
    "def remove_words_after_3rd(text):\n",
    "    words = text.split()\n",
    "    words = words[:3]\n",
    "    return \" \".join(words)\n",
    "\n",
    "df['user'] = df['user'].apply(remove_words_after_3rd)\n",
    "\n",
    "#Define a function to compare the first 4 words of \"user\" and \"tweet\" columns\n",
    "def compare_and_replace(row):\n",
    "    user_words = row[\"user\"].split()[:3]\n",
    "    tweet_words = row[\"tweet\"].split()[:3]\n",
    "\n",
    "    if user_words == tweet_words:\n",
    "        return \"unknown user\"\n",
    "    else:\n",
    "        return row[\"user\"]\n",
    "\n",
    "# Apply the function to create a new \"user\" column with the changes\n",
    "df[\"user\"] = df.apply(compare_and_replace, axis=1)\n",
    "\n",
    "#Deleting images\n",
    "# Remove rows where the \"user\" column begins with \"file:///var/mobile/Library/\"\n",
    "df = df[~df['user'].str.startswith(\"file:///var/mobile/Library/\")]\n",
    "\n",
    "#Remove 'Xcom' from every row in the \"user\" column\n",
    "df['user'] = df['user'].str.replace('Xcom', '')\n",
    "\n",
    "\n",
    "#Display only the first column\n",
    "#print(df.iloc[:, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "11baeb27-4e73-46fe-a3d7-e8d453ce073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming the user column name to 'name'\n",
    "df = df.rename(columns={'user': 'name'})\n",
    "#checking it\n",
    "#print(df[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f233d44d-b217-4b64-9e6f-7aa539ff7439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the tweet column\n",
    "\n",
    "# Replace \"Embedded video\" and everything after it with an empty string\n",
    "df['tweet'] = df['tweet'].str.replace(r'Embedded video[^\\n]*', '', regex=True)\n",
    "\n",
    "# Remove everything after 'Reposts' (including 'Reposts')\n",
    "df['tweet'] = df['tweet'].str.split('Reposts').str[0]\n",
    "\n",
    "df['tweet'] = df['tweet'].str.replace(r'Â·[^\\n]*', '', regex=True)\n",
    "\n",
    "# Function to clean the tweet column\n",
    "def clean_tweet(tweet):\n",
    "    # Use Unicode escape sequence for '·' to handle different encodings\n",
    "    cleaned_tweet = tweet.split('\\u00b7')[0]\n",
    "    return cleaned_tweet.strip()\n",
    "\n",
    "# Apply the clean_tweet function to the 'tweet' column\n",
    "df['tweet'] = df['tweet'].apply(clean_tweet)\n",
    "\n",
    "# Function to remove all emojis from a tweet\n",
    "def remove_emojis(tweet):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "                               u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "                               u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "                               u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                               u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "                               u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                               u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "                               u\"\\U000024C2-\\U0001F251\" \n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', tweet)\n",
    "\n",
    "# Apply the remove_emojis function to the 'tweet' column\n",
    "df['tweet'] = df['tweet'].apply(remove_emojis)\n",
    "\n",
    "# Function to remove the specified pattern\n",
    "def remove_pattern(tweet):\n",
    "    pattern = re.compile(r'Born [A-Za-z]+ \\d+ Joined [A-Za-z]+ \\d{4}\\. \\d+ Following')\n",
    "    return pattern.sub('', tweet)\n",
    "\n",
    "# Apply the remove_pattern function to the 'tweet' column\n",
    "df['tweet'] = df['tweet'].apply(remove_pattern)\n",
    "\n",
    "# Function to remove the specified pattern\n",
    "def remove_pattern(tweet):\n",
    "    pattern = re.compile(r'Joined [A-Za-z]+ \\d{4}\\. \\d+ Following')\n",
    "    return pattern.sub('', tweet)\n",
    "\n",
    "# Apply the remove_pattern function to the 'tweet' column\n",
    "df['tweet'] = df['tweet'].apply(remove_pattern)\n",
    "\n",
    "# Function to remove the specified pattern\n",
    "def remove_pattern(tweet):\n",
    "    pattern = re.compile(r'Quote\\. Square profile picture ,Discord: .*? ,linktr\\.ee/[^ ]* Joined [A-Za-z]+ \\d{4}\\. \\d+:\\d+ [APMapm]+ ,')\n",
    "    return pattern.sub('', tweet)\n",
    "\n",
    "# Apply the remove_pattern function to the 'tweet' column\n",
    "df['tweet'] = df['tweet'].apply(remove_pattern)\n",
    "\n",
    "# Function to remove datetime formats\n",
    "def remove_datetime_formats(tweet):\n",
    "    # Match common datetime formats\n",
    "    datetime_pattern = re.compile(r'\\b\\d{1,2}[:]\\d{1,2}([:\\d{1,2}]*)?[ ]?(?:AM|PM)?\\b|'\n",
    "                                  r'\\b\\d{1,2}[/]\\d{1,2}[/]\\d{2,4}\\b|'\n",
    "                                  r'\\b(?:Sun|Mon|Tue|Wed|Thu|Fri|Sat)[a-zA-Z]*,? [A-Za-z]+ \\d{1,2},? \\d{2,4}\\b|'\n",
    "                                  r'\\b\\d{1,2}[/]\\d{1,2}[/]\\d{2,4} \\d{1,2}[:]\\d{1,2}([:\\d{1,2}]*)?[ ]?(?:AM|PM)?\\b')\n",
    "\n",
    "    return datetime_pattern.sub('', tweet)\n",
    "\n",
    "# Apply the remove_datetime_formats function to the 'tweet' column\n",
    "df['tweet'] = df['tweet'].apply(remove_datetime_formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "8a63e7b4-7491-4276-8165-eea6bb7d5a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the last row (username)\n",
    "\n",
    "# Extract the desired part using a regular expression\n",
    "df['username'] = df['username'].str.extract(r'https://twitter.com › (\\S+) › status', expand=False)\n",
    "\n",
    "# Check and fill missing values in the \"username\" column\n",
    "df['username'] = df.apply(lambda row: row['twitterlink'].replace('https://twitter.com/', '').\n",
    "                          split('/status/')[0] if pd.isnull(row['username']) else row['username'], axis=1)\n",
    "\n",
    "# Clean the \"username\" column\n",
    "df['username'] = df['username'].str.replace('https://twitter.com/', '').str.replace('/status/.*', '')\n",
    "\n",
    "# Display the updated DataFrame\n",
    "#print(df['username'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6cd4309e-5cef-4c2d-998f-d0df83eec15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns\n",
    "#print(df.head(10))\n",
    "#print(df.iloc[1600, 0])\n",
    "#print(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "4d760113-a860-458a-bdcb-f15842dd5ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving as csv file \n",
    "# Assuming your DataFrame is named df\n",
    "df.to_csv('cleaned_dataset.csv', index=False)\n",
    "\n",
    "#checking_if_saved_file_is_empty = pd.read_csv(\"updated_twitter_data_after_cleaning_process.csv\")\n",
    "#print(checking_if_saved_file_is_empty.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f507080-a588-4df1-826f-56e534aa3311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
