{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4345daf5-78ef-4d7e-93e6-e1601c3ef7de",
   "metadata": {},
   "source": [
    "**TWITTER SENTIMENT ANALYSIS PROJECT USING PYTHON**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380c8723-0b4c-4ad6-97e9-e0af415c8825",
   "metadata": {},
   "source": [
    "**DATA EXTRACTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a27112b-aef8-4156-b744-483a660eedb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:\\\\Users\\\\HP\\\\Desktop\\\\Twitter Project\"\n",
    "\n",
    "#importing libraries \n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "#api_key = \"b8124e2ee60dd1ba68b9c1b0831f877d\"\n",
    "#api_key = \"421a734e7a50598d27e343fe84061467\"\n",
    "api_key = \"d88512e4037519e1e5e33a5e7ebb7708\"\n",
    "query = \"VAR\"\n",
    "\n",
    "# Number of tweets to retrieve per request\n",
    "num_per_request = 100  \n",
    "\n",
    "\n",
    "# Total number of tweets to retrieve\n",
    "total_tweets = 5000\n",
    "\n",
    "#creating an empty list to store all retrieved tweets\n",
    "all_tweets = []\n",
    "#api call\n",
    "\n",
    "# Make multiple API calls to retrieve the specified number of tweets\n",
    "for i in range(0, total_tweets, num_per_request):\n",
    "    payload = {\n",
    "        \"api_key\": api_key,\n",
    "        \"query\": query,\n",
    "        \"num\": num_per_request,\n",
    "        \"start\": i  # Start index for retrieving tweets\n",
    "    }\n",
    "\n",
    "    response = requests.get(\"http://api.scraperapi.com/structured/twitter/search\", params=payload)\n",
    "    data = response.json()\n",
    "\n",
    "    # Add retrieved tweets to the list\n",
    " #   all_tweets.extend(data[\"results\"])\n",
    "\n",
    "#print(f\"Retrieved {len(all_tweets)} tweets.\")\n",
    "data.keys()\n",
    "data['organic_results'][0]\n",
    "\n",
    "\n",
    "twitter_data = data['organic_results']\n",
    "for tweets in twitter_data:\n",
    "    twitter_data.append(tweets)\n",
    "\n",
    "df = pd.DataFrame(twitter_data)\n",
    "# Save the DataFrame to a CSV file\n",
    "#df.to_csv('C:\\Users\\HP\\Desktop\\Twitter Project/twitter_datasets.csv', index=False)\n",
    "df.to_csv('C:\\\\Users\\\\HP\\\\Desktop\\\\Twitter Project\\\\twitter_datasets.csv', index=False)\n",
    "\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3f910f-db09-473d-bd73-2f4edbd8e44a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
