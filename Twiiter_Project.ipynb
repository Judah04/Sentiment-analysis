{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4345daf5-78ef-4d7e-93e6-e1601c3ef7de",
   "metadata": {},
   "source": [
    "**TWITTER SENTIMENT ANALYSIS PROJECT USING PYTHON**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380c8723-0b4c-4ad6-97e9-e0af415c8825",
   "metadata": {},
   "source": [
    "**DATA VALIDATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a27112b-aef8-4156-b744-483a660eedb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries \n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "#api_key = \"b8124e2ee60dd1ba68b9c1b0831f877d\"\n",
    "api_key = \"421a734e7a50598d27e343fe84061467\"\n",
    "\n",
    "query = \"VAR\"\n",
    "\n",
    "# Number of tweets to retrieve per request\n",
    "num_per_request = 100  \n",
    "\n",
    "\n",
    "# Total number of tweets to retrieve\n",
    "total_tweets = 10000\n",
    "\n",
    "#creating an empty list to store all retrieved tweets\n",
    "all_tweets = []\n",
    "#api call\n",
    "\n",
    "# Make multiple API calls to retrieve the specified number of tweets\n",
    "for i in range(0, total_tweets, num_per_request):\n",
    "    payload = {\n",
    "        \"api_key\": api_key,\n",
    "        \"query\": query,\n",
    "        \"num\": num_per_request,\n",
    "        \"start\": i  # Start index for retrieving tweets\n",
    "    }\n",
    "\n",
    "    response = requests.get(\"http://api.scraperapi.com/structured/twitter/search\", params=payload)\n",
    "    data = response.json()\n",
    "\n",
    "    # Add retrieved tweets to the list\n",
    " #   all_tweets.extend(data[\"results\"])\n",
    "\n",
    "#print(f\"Retrieved {len(all_tweets)} tweets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772d9dcf-b0a7-4406-be1e-b0b460485ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f0a6dd-9f57-414e-bf92-356d01ecc018",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052ed4f5-1d3b-4449-9c22-cc84e074b980",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f13a66b-b12b-4791-a1b6-d9d1aa7782e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['organic_results'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372c0dfe-766f-44bb-a4a0-de4354ad5b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data = data['organic_results']\n",
    "for tweets in twitter_data:\n",
    "    twitter_data.append(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb3c1cc-fe44-4c53-b08f-871d2d2eae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(twitter_data)\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('twitter_datasets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10336186-7338-4168-bd8f-7a72a5de3af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed80f04-6625-4fd4-953c-27331ea1a999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
